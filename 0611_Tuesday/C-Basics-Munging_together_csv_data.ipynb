{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Munging together .csv data #\n",
    "\n",
    "It's very common to see tabular or field-based data (pretty much anything you could imagine putting in a spreadsheet) distributed in the form of .csv or .tsv (comma- or tab-separated value) files. While you can open these delimited files with a spreadsheet program like Microsoft's Excel, they are simply plain-text files, which means they can be opened by any text editor, making them lightweight and platform-independent: perfect for data interchange.\n",
    "\n",
    "In this exercise, we're going to start with two different .csv files that have different pieces of information we want about some of the same books. The first file is the .csv with ESTC bibliographic data about books printed by William Bowyer (which you exported from MarcEdit). The second file provides metadata for TEI-encoded texts created as part of the ECCO-TCP (Text Creationship Partnership) project.\n",
    "\n",
    "Each file has something that the other doesn't. The ESTC file lets us know which eighteenth-century books were printed by Bowyer but doesn't give us any information about how to get the text. The TCP metadata file tells us how to get the text, but doesn't tell us anything about which texts were printed by Bowyer. But both files include some common data--crucially, an ESTC citation number--that we can use to connect the two sets of information.\n",
    "\n",
    "We'll read the file of Bowyer-connected ESTC records to get their ESTC numbers, look for those ESTC numbers in the file of TCP metadata, and produce a new file that adds a TCP identifer to our ESTC metadata.\n",
    "\n",
    "*Note:* This code was written to prioritize breaking things down into small, relatively discrete steps. There are ways it could be made more concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, where are you running this notebook? ##\n",
    "\n",
    "These notebooks were first written for use in L-100 (Digital Approaches to Bibliography and Book history) at Rare Book School in 2018. If you were a student in that course, you received an image of a virtual machine running Ubuntu Linux, along with the files that the various Jupyter Notebooks work with. If you've come to this notebook from a link at GitHub to MyBinder, you won't have those files, but I've added them to GitHub. \n",
    "\n",
    "NOTE: If you're running this notebook from the RBSDigitalApproaches2018 virtual machine, you'll need to be sure that you're running `jupyter notebook` with either the `marc` or `web-scraping` virtualenv activated. If you run into errors below related to missing libraries, quite the notebook and Jupyter Notebooks, go back to your terminalk and execute `workon marc` or `workon web-scraping` to activate that virtualenv. (If another virtualenv is active, you may have to execute `deactivate` first.)\n",
    "\n",
    "The first thing we need to do is to determine what file paths to use in the rest of the code below. Simply comment or uncomment the appropriate line by adding or deleting the octothorpe (#) at the beginning of the line, then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this notebook from the RBSDigitalApproaches2018 virtual machine\n",
    "# in VirtualBox, make sure the line below is uncommented (that's the default for this\n",
    "# notebook.)\n",
    "location = 'rbs_virtual_machine'\n",
    "\n",
    "# If you're running this notebook at MyBinder using a link from the GitHub repository,\n",
    "# comment out line 4, above, and uncomment line 8, below:\n",
    "#location = 'mybinder'\n",
    "\n",
    "if location == 'rbs_virtual_machine' :\n",
    "    input_path = '/media/sf_RBSDigitalApproaches/data/0611_Tuesday_data/'\n",
    "    output_path = '/media/sf_RBSDigitalApproaches/output/'\n",
    "elif location == 'mybinder' :\n",
    "    input_path = 'data/'\n",
    "    output_path = 'output/'\n",
    "    # If you're running this notebook at MyBinder.org, the code on this page will end up\n",
    "    # writing files to the \"output\" folder. To download the files you create, go to the \n",
    "    # Jupyter Notebook \"Home\" tab for the repository, enter the \"output\" folder, click \n",
    "    # on the filename of the file you created, then click the \"Download\" button."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get the ESTC numbers of texts printed by William Bowyer ##\n",
    "\n",
    "We'll get the ESTC numbers of texts printed by William Bowyer from the .csv file we exported from MarcEdit earlier and save them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the csv library\n",
    "import csv\n",
    "# Create an empty list to hold our ESTC numbers\n",
    "estc_nums = []\n",
    "\n",
    "# A workaround to make this notebook available at MyBinder.org. If you're working in the\n",
    "# RBSDigitalApproaches2018 virtual machine, we saved the Bowyer .csv file to \"output\".\n",
    "# If you're note sure where your .csv file ended up, you can change your location in the\n",
    "# code block above, then re-run it.\n",
    "if location == 'rbs_virtual_machine' :\n",
    "    path = output_path\n",
    "elif location == 'mybinder' :\n",
    "    path = input_path\n",
    "\n",
    "# Open the .csv file of ESTC bibliographic data.\n",
    "with open(path + 'Bowyer_from_ESTC-full.csv', 'r') as estcfile:\n",
    "    # Initiate a csv DictReader\n",
    "    estcreader = csv.DictReader(estcfile, delimiter=',', quotechar='\"')\n",
    "    # Read through the .csv file a line at a time\n",
    "    for row in estcreader :\n",
    "        # Get the ESTC number from the '001 cell\n",
    "        estc_num = row['001']\n",
    "        # Check to see if the ESTC number is already in our list of ESTC numbers...\n",
    "        if estc_num not in estc_nums :\n",
    "            # If it's not, add it to the list\n",
    "            estc_nums.append(estc_num)\n",
    "\n",
    "# Sort the list in place. No good reason. I'm just funny that way.\n",
    "estc_nums.sort()\n",
    "\n",
    "# Let's print our list and see what we have.\n",
    "print(estc_nums)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get TCP ids for the ESTC numbers we just found ##\n",
    "\n",
    "We'll search through our second .csv file of ECCO-TCP metadata looking for the ESTC numbers we just found. When we find one of those ESTC numbers, we'll store it and its corresponding TCP identifier in a dictionary, with the ESTC number as the key and the TCP number as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store our matched ESTC numbers and the TCP ids that correspond to them\n",
    "estc_tcp = {}\n",
    "# Open our .csv file of ECCO-TCP metadata\n",
    "with open(input_path + 'ecco_tcp_ids.csv', 'r') as tcpfile :\n",
    "    # Initiate a csv DictReader\n",
    "    tcpreader = csv.DictReader(tcpfile, delimiter=',', quotechar='\"')\n",
    "    # Read through the .csv file a line at a time\n",
    "    for row in tcpreader :\n",
    "        # Find the ESTC number\n",
    "        estc_num = row['ESTC_Number']\n",
    "        # Check to see if this ESTC number is in the list of Bowyer ESTC numbers we created in step 1...\n",
    "        if estc_num in estc_nums :\n",
    "            # If it is, create an entry in our estc_tcp dictionary, with the ESTC number as the key and the \n",
    "            # TCP id as the value\n",
    "            estc_tcp[estc_num] = row['TCP_Number']\n",
    "\n",
    "# Let's see what we have.            \n",
    "print(estc_tcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Write our matched ESTC data to a new .csv file, adding a column with the TCP id ##\n",
    "\n",
    "Now it's time to write our matches to a file (we'll use this file later to identify TCP texts to download). Mostly, we're just going to copy relevant rows from one .csv file to another, but we need to add a new column. This led me to a solution that strikes me as actually a little confusing, which I'll try to explain in the comments. As always, there may well be a more \"Pythonic\" solution, but this is the one that occurred to me.\n",
    "\n",
    "I've commented out several lines that perform the real business of this section so that we can see each of the steps involved:\n",
    "1) Run the cell to see the fieldnames that get generated, then comment out line 17.\n",
    "2) Uncomment line 34 and run the cell again to see results that we're constructing before we write out the file. Then comment out line 34 again.\n",
    "3) Uncomment lines 18, 19, and 35 and run the cell again to actually write our new .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the .csv file of Bowyer records again (this is one of the inefficiencies of this script in its current\n",
    "# form--we could probably figure out a way to do this all in one pass), and create a new .csv file to hold our\n",
    "# output.\n",
    "with open(path + 'Bowyer_from_ESTC-full.csv', 'r') as bibdata, \\\n",
    "open(output_path + 'Bowyer_TCP_texts.csv', 'w') as outfile :\n",
    "    # Initiate a csv DictReader\n",
    "    reader = csv.DictReader(bibdata, delimiter=',', quotechar='\"')\n",
    "    # Begin getting the fieldnames for our new file by getting the keys from the first row of the .csv file\n",
    "    # (reader.next() gets the first row, .keys() gets the keys--DictReader reads each row and holds its \n",
    "    # values as a dictionary of key/value pairs). Dictionaries are, by nature, unsorted, so our keys would\n",
    "    # come back in some random order. That wouldn't be a problem, but I've sorted the keys because otherwise\n",
    "    # I'd be haunted by the untidiness of it all.\n",
    "    fieldnames = sorted(reader.next().keys())\n",
    "    # Add a column heading for our TCP ids by inserting a new item to our list of fieldnames at index [1] \n",
    "    # (i.e., make it the second item in the list)\n",
    "    fieldnames.insert(1,'tcp_id')\n",
    "    print(fieldnames)\n",
    "    #writer = csv.DictWriter(outfile, delimiter=',', fieldnames = fieldnames)\n",
    "    #writer.writeheader()\n",
    "    \n",
    "    # Read through the .csv file of Bowyer bibliographic data a line at a time\n",
    "    for row in reader :\n",
    "        # Get the ESTC number\n",
    "        estc_num = row['001']\n",
    "        # Check to see if that ESTC number is among the keys in our ecco_tcp dictionary...\n",
    "        if estc_num in estc_tcp.keys() :\n",
    "            # If it is, copy the row (that is, assign the entire row to a new variable called outrow). Keep in\n",
    "            # mind that, because we're working with DictReader, our row is a dictionary rather than a list.\n",
    "            outrow = row\n",
    "            # Now, add a new key/value pair to our outrow dictionary, with 'tcp_id' as the key (to correspond to\n",
    "            # the column heading we added in line 17), and the value in our estc_tcp dictionary that has this\n",
    "            # this ESTC number as its key\n",
    "            outrow['tcp_id'] = estc_tcp[estc_num]\n",
    "            #print(outrow)\n",
    "            #writer.writerow(outrow)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
